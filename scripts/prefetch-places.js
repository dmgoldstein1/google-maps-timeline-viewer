#!/usr/bin/env node

/**
 * Generated by GitHub Copilot (GPT-5)
 * 
 * Prefetch CLI script for Google Maps Timeline Viewer
 * Batch fetches place details and photos from Google Places API
 * 
 * Features:
 * - Worker pool with configurable concurrency
 * - Rate limiting to respect API quotas
 * - Safe deletion (only after successful re-fetch)
 * - Comprehensive error handling with retry logic
 * - Progress tracking and logging
 * 
 * Usage:
 *   node scripts/prefetch-places.js --input timeline.json
 *   node scripts/prefetch-places.js --all
 */

import { Command } from 'commander';
import { readFile } from 'fs/promises';
import PQueue from 'p-queue';
import fetch from 'node-fetch';
import pino from 'pino';
import {
  initDatabase,
  getCachedPlace,
  setCachedPlace,
  setCachedPhoto,
  incrementApiUsage,
  isQuotaExceeded,
  getAllCachedPlaceIds,
  isExpired
} from '../server/db.js';
import { detectFormat, extractPlaceIds } from '../server/format-detector.js';
import { initPhotosDirectory, processPhoto, deletePlacePhotos } from '../server/image-processor.js';

const logger = pino({
  level: process.env.LOG_LEVEL || 'info',
  transport: {
    target: 'pino-pretty',
    options: { colorize: true }
  }
});

const program = new Command();

program
  .name('prefetch-places')
  .description('Prefetch place details and photos from Google Places API')
  .option('-i, --input <file>', 'Timeline JSON file to process')
  .option('-a, --all', 'Prefetch all expired cache entries')
  .option('-c, --concurrency <number>', 'Number of concurrent workers', '5')
  .option('-d, --delay <ms>', 'Delay between requests per worker (ms)', '200')
  .option('--dry-run', 'Show what would be fetched without making API calls')
  .parse(process.argv);

const options = program.opts();

/**
 * Get Google Maps API key
 */
async function getApiKey() {
  const keyFile = process.env.GOOGLE_MAPS_API_KEY_FILE;
  
  if (keyFile) {
    try {
      const key = await readFile(keyFile, 'utf-8');
      return key.trim();
    } catch (error) {
      logger.error({ error: error.message }, 'Failed to read API key from file');
    }
  }
  
  return process.env.GOOGLE_MAPS_API_KEY || '';
}

/**
 * Fetch place details from Google Places API
 */
async function fetchPlaceFromGoogle(placeId, apiKey) {
  const url = `https://places.googleapis.com/v1/places/${placeId}`;
  const fields = [
    'id',
    'displayName',
    'formattedAddress',
    'location',
    'svgIconMaskURI',
    'iconBackgroundColor',
    'googleMapsURI',
    'types',
    'photos'
  ];
  
  const response = await fetch(url, {
    method: 'GET',
    headers: {
      'X-Goog-Api-Key': apiKey,
      'X-Goog-FieldMask': fields.join(',')
    }
  });
  
  if (!response.ok) {
    const error = await response.text();
    throw new Error(`Places API error: ${response.status} - ${error}`);
  }
  
  return await response.json();
}

/**
 * Fetch photo from Google Places API
 */
async function fetchPhotoFromGoogle(photoName, apiKey, maxWidth = 1200) {
  const url = `https://places.googleapis.com/v1/${photoName}/media?maxWidthPx=${maxWidth}&key=${apiKey}`;
  
  const response = await fetch(url);
  
  if (!response.ok) {
    throw new Error(`Photo API error: ${response.status}`);
  }
  
  return await response.buffer();
}

/**
 * Process a single place
 */
async function processPlace(placeId, apiKey, delay) {
  try {
    // Check if quota exceeded
    if (isQuotaExceeded()) {
      logger.warn('API quota exceeded, stopping');
      return { success: false, placeId, error: 'Quota exceeded' };
    }
    
    // Fetch from API
    logger.debug({ placeId }, 'Fetching place from Google Places API');
    const placeData = await fetchPlaceFromGoogle(placeId, apiKey);
    
    // Increment usage
    incrementApiUsage();
    
    // Prepare cache data
    const cacheData = {
      displayName: placeData.displayName?.text,
      formattedAddress: placeData.formattedAddress,
      location: placeData.location,
      svgIconMaskURI: placeData.svgIconMaskURI,
      iconBackgroundColor: placeData.iconBackgroundColor,
      googleMapsURI: placeData.googleMapsURI,
      types: placeData.types
    };
    
    // Cache place data (safe: only written after successful fetch)
    setCachedPlace(placeId, cacheData);
    logger.info({ placeId, name: cacheData.displayName }, 'Place cached');
    
    // Process photos
    let photoSuccess = false;
    if (placeData.photos && placeData.photos.length > 0) {
      try {
        logger.debug({ placeId }, 'Fetching photo');
        const photoBuffer = await fetchPhotoFromGoogle(placeData.photos[0].name, apiKey);
        
        incrementApiUsage();
        
        // Process photo (generates all sizes and formats)
        const photoResult = await processPhoto(photoBuffer, placeId);
        
        if (photoResult.success) {
          // Only delete old photos after successful processing
          setCachedPhoto(placeId, photoResult.hasWebP, photoResult.hasJPEG, photoResult.sizes);
          photoSuccess = true;
          logger.info({ placeId, sizes: photoResult.sizes }, 'Photo processed');
        }
      } catch (photoError) {
        logger.error({ placeId, error: photoError.message }, 'Photo processing failed');
      }
    }
    
    // Rate limiting delay
    await new Promise(resolve => setTimeout(resolve, delay));
    
    return {
      success: true,
      placeId,
      hasPhoto: photoSuccess,
      name: cacheData.displayName
    };
    
  } catch (error) {
    logger.error({ placeId, error: error.message }, 'Failed to process place');
    
    // Implement exponential backoff retry for rate limit errors
    if (error.message.includes('429')) {
      logger.warn({ placeId }, 'Rate limited, will retry');
      await new Promise(resolve => setTimeout(resolve, delay * 5));
      throw error; // Let p-queue retry
    }
    
    return {
      success: false,
      placeId,
      error: error.message
    };
  }
}

/**
 * Main prefetch function
 */
async function prefetch() {
  try {
    logger.info('Starting prefetch operation');
    
    // Initialize database and photos directory
    await initDatabase();
    await initPhotosDirectory();
    
    // Get API key
    const apiKey = await getApiKey();
    if (!apiKey) {
      logger.error('Google Maps API key not configured');
      process.exit(1);
    }
    
    // Determine which place IDs to fetch
    let placeIds = [];
    
    if (options.input) {
      // Load from timeline file
      logger.info({ file: options.input }, 'Loading timeline file');
      const content = await readFile(options.input, 'utf-8');
      const data = JSON.parse(content);
      
      const detection = detectFormat(data);
      logger.info({ format: detection.format, confidence: detection.confidence }, 'Format detected');
      
      placeIds = extractPlaceIds(data, detection.format);
      logger.info({ count: placeIds.length }, 'Place IDs extracted');
      
    } else if (options.all) {
      // Re-fetch expired entries
      const cachedIds = getAllCachedPlaceIds();
      placeIds = cachedIds.filter(id => {
        const cached = getCachedPlace(id);
        return cached && isExpired(cached.cached_at);
      });
      logger.info({ count: placeIds.length }, 'Expired cache entries found');
      
    } else {
      logger.error('Either --input or --all must be specified');
      process.exit(1);
    }
    
    if (placeIds.length === 0) {
      logger.info('No places to fetch');
      return;
    }
    
    // Filter out already cached non-expired places
    const cachedIds = getAllCachedPlaceIds();
    const uncachedIds = placeIds.filter(id => {
      if (!cachedIds.includes(id)) return true;
      const cached = getCachedPlace(id);
      return cached && isExpired(cached.cached_at);
    });
    
    logger.info({
      total: placeIds.length,
      cached: placeIds.length - uncachedIds.length,
      toFetch: uncachedIds.length
    }, 'Cache status');
    
    if (options.dryRun) {
      logger.info('Dry run mode - no API calls will be made');
      logger.info({ placeIds: uncachedIds.slice(0, 10) }, 'Sample place IDs');
      return;
    }
    
    // Create worker queue
    const concurrency = parseInt(options.concurrency);
    const delay = parseInt(options.delay);
    
    const queue = new PQueue({
      concurrency,
      interval: delay,
      intervalCap: 1
    });
    
    logger.info({ concurrency, delay }, 'Worker pool configured');
    
    // Track progress
    let completed = 0;
    let successful = 0;
    let failed = 0;
    const errors = [];
    
    const startTime = Date.now();
    
    // Process all places
    const results = await queue.addAll(
      uncachedIds.map(placeId => async () => {
        const result = await processPlace(placeId, apiKey, delay);
        
        completed++;
        if (result.success) {
          successful++;
        } else {
          failed++;
          errors.push(result);
        }
        
        // Log progress every 10 places
        if (completed % 10 === 0) {
          const elapsed = (Date.now() - startTime) / 1000;
          const rate = completed / elapsed;
          const remaining = uncachedIds.length - completed;
          const eta = remaining / rate;
          
          logger.info({
            completed,
            total: uncachedIds.length,
            successful,
            failed,
            rate: rate.toFixed(2) + '/s',
            eta: Math.round(eta) + 's'
          }, 'Progress update');
        }
        
        return result;
      })
    );
    
    // Final summary
    const totalTime = (Date.now() - startTime) / 1000;
    
    logger.info({
      total: uncachedIds.length,
      successful,
      failed,
      duration: totalTime.toFixed(2) + 's',
      rate: (completed / totalTime).toFixed(2) + '/s'
    }, 'Prefetch completed');
    
    if (errors.length > 0) {
      logger.warn({ errors: errors.slice(0, 10) }, 'Sample errors');
    }
    
  } catch (error) {
    logger.error({ error: error.message, stack: error.stack }, 'Prefetch failed');
    process.exit(1);
  }
}

// Run prefetch
prefetch();
